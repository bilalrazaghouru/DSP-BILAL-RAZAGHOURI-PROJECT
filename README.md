# üß† DSP Project ‚Äì FastAPI + Streamlit + Airflow + PostgreSQL

A complete **end-to-end data automation project** integrating:
- FastAPI for model predictions  
- Streamlit for interactive UI  
- Airflow for orchestration (data ingestion & prediction pipelines)  
- PostgreSQL (Docker) for storing all data  
- SQLAlchemy ORM for easy database interaction

---

## üìÅ Project Structure

DSP-BILAL-RAZAGHOURI-PROJECT/
‚îÇ
‚îú‚îÄ‚îÄ api/ # FastAPI backend
‚îÇ ‚îú‚îÄ‚îÄ main.py
‚îÇ ‚îú‚îÄ‚îÄ models.py
‚îÇ ‚îú‚îÄ‚îÄ database.py
‚îÇ ‚îî‚îÄ‚îÄ create_tables.py
‚îÇ
‚îú‚îÄ‚îÄ webapp/ # Streamlit app
‚îÇ ‚îî‚îÄ‚îÄ app.py
‚îÇ
‚îú‚îÄ‚îÄ dags/ # Airflow DAGs
‚îÇ ‚îú‚îÄ‚îÄ prediction_dag.py
‚îÇ ‚îî‚îÄ‚îÄ ingest_dag.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/ # Utility scripts
‚îÇ ‚îî‚îÄ‚îÄ generate_data.py
‚îÇ
‚îú‚îÄ‚îÄ data/ # Main dataset
‚îÇ ‚îî‚îÄ‚îÄ main.csv
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ docker-compose.yaml
‚îî‚îÄ‚îÄ README.md

## ‚öôÔ∏è Technologies Used

| Tool | Purpose |
|------|----------|
| **Python** | Main programming language |
| **FastAPI** | Backend API for predictions |
| **Streamlit** | Web dashboard for user interface |
| **Airflow** | Automates ingestion & prediction tasks |
| **PostgreSQL (Docker)** | Database for predictions & stats |
| **SQLAlchemy** | ORM for database access |

---

## üîÑ Workflow Overview

1Ô∏è‚É£ **Data Generation** ‚Üí `scripts/generate_data.py` creates raw CSV files  
2Ô∏è‚É£ **Ingestion DAG** ‚Üí reads raw data ‚Üí validates ‚Üí saves stats ‚Üí moves good/bad data  
3Ô∏è‚É£ **Prediction DAG** ‚Üí detects new files ‚Üí calls FastAPI ‚Üí stores predictions  
4Ô∏è‚É£ **Streamlit App** ‚Üí make live predictions and view past results  
5Ô∏è‚É£ **PostgreSQL** stores all predictions and data quality stats

---

## üóÇÔ∏è Database Models

### Prediction
Stores every prediction made by API or DAG.

| Column | Description |
|---------|-------------|
| id | Auto ID |
| created_at | Timestamp |
| source | webapp / scheduled |
| features | Input features |
| prediction | Output result |

### DataQualityStat
Stores quality metrics for each ingested file.

| Column | Description |
|---------|-------------|
| file_name | CSV name |
| record_count | Number of rows |
| null_rate | % of missing values |
| criticality | low / medium / high |
| summary | Short summary text |

---

## üöÄ How to Run the Project

### 1Ô∏è‚É£ Start PostgreSQL (Docker)

docker start dsp-pg 2>/dev/null || docker run --name dsp-pg \
-e POSTGRES_USER=dsp -e POSTGRES_PASSWORD=dsp -e POSTGRES_DB=dsp \
-p 5432:5432 -d postgres:16
2Ô∏è‚É£ Create environment & install requirements

python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
3Ô∏è‚É£ Create tables

export DATABASE_URL="postgresql+psycopg2://dsp:dsp@localhost:5432/dsp"
python api/create_tables.py
4Ô∏è‚É£ Run FastAPI

python -m uvicorn api.main:app --reload --port 8000
5Ô∏è‚É£ Run Streamlit

streamlit run webapp/app.py
6Ô∏è‚É£ Run Airflow

source ~/airflow-venv/bin/activate
export AIRFLOW_HOME="$HOME/airflow_home"
airflow scheduler
airflow webserver --port 8081

üë• Team Members
Name	Role	Branch
Bilal Razaghouru	Project Lead (API, DB, Integration)	main
Member 1 (Ahmad)	Streamlit UI	streamlit-branch
Member 2 (Fahad)	Airflow DAGs	dag-branch
Member 3 (Vinood)	Airflow Setup / Validation	airflow-branch

‚úÖ Project Highlights
Fully automated ML pipeline

Works end-to-end: ingestion ‚Üí prediction ‚Üí visualization

Real-time UI + database integration

Collaborative version control with Git branches

üèÅ Results
Streamlit shows live predictions

Airflow automates data movement

PostgreSQL stores data-quality stats

Each team member‚Äôs contribution visible on GitHub

Streamlit app running

Airflow DAG view

Database table view

üßæ License
This project is for academic and learning purposes under the guidance of the DSP course.



---

Would you like me to create this README as a **ready-to-download file (`README.md`)** so you can directly upload it to GitHub?
